{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/home/lngo/mySpark/spark-2.0.2-bin-hadoop2.7\"\n"
     ]
    }
   ],
   "source": [
    "if (nchar(Sys.getenv(\"SPARK_HOME\")) < 1) {\n",
    "  Sys.setenv(SPARK_HOME = \"/home/lngo/mySpark/spark-2.0.2-bin-hadoop2.7\")\n",
    "}\n",
    "print(Sys.getenv(\"SPARK_HOME\"))\n",
    "spark_submit_args <- paste(\"--master spark://node1903:7077\",\n",
    "                           \"--executor-memory 2g\",\n",
    "                           \"--num-executors 3\",\n",
    "                           \"--executor-cores 4\",\n",
    "                           paste(\"--conf spark.executorEnv.PATH=\",\n",
    "                                 paste(Sys.getenv(\"PATH\"),\n",
    "                                       \"/usr/local/share/jupyterhub/env/R/bin\",sep=\":\"),\n",
    "                                 sep=\"\"),\n",
    "                           \"sparkr-shell\",sep=\" \")\n",
    "\n",
    "Sys.setenv(\"SPARKR_SUBMIT_ARGS\"=spark_submit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘SparkR’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    cov, filter, lag, na.omit, predict, sd, var, window\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.data.frame, colnames, colnames<-, drop, endsWith, intersect,\n",
      "    rank, rbind, sample, startsWith, subset, summary, transform, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(SparkR, lib.loc = c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spark package found in SPARK_HOME: /home/lngo/mySpark/spark-2.0.2-bin-hadoop2.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching java with spark-submit command /home/lngo/mySpark/spark-2.0.2-bin-hadoop2.7/bin/spark-submit  --packages com.databricks:spark-csv_2.11:1.2.0 --master spark://node1903:7077 --executor-memory 2g --num-executors 3 --executor-cores 4 --conf spark.executorEnv.PATH=/software/hdf5/1.10.0/bin:/software/openmpi/1.10.3_gcc610/bin:/software/gcc/5.3.0/bin:/software/zeromq/4.1.5/bin:/software/matlab/R2015a/toolbox/distcomp/bin:/software/matlab/R2015a/bin/glnxa64:/software/matlab/R2015a/bin:/software/anaconda3/4.2.0/bin:/usr/lib64/qt-3.3/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/opt/mx/bin:/opt/pbs/default/bin:/opt/pbs/default/sbin:/home/lngo/bin:/usr/local/share/jupyterhub/env/R/bin sparkr-shell /local_scratch/pbs.7808498.pbs02/RtmpLzgsZf/backend_port2bea3540e46b \n"
     ]
    }
   ],
   "source": [
    "sc <- sparkR.session(sparkPackages=\"com.databricks:spark-csv_2.11:1.2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“'sparkRSQL.init' is deprecated.\n",
      "Use 'sparkR.session' instead.\n",
      "See help(\"Deprecated\")”"
     ]
    }
   ],
   "source": [
    "sqlContext <- sparkRSQL.init(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.009   0.000  16.338 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ptm <- proc.time()\n",
    "movielens <- read.json(\"/home/lngo/intro-to-hadoop/movielens/ratings.csv\")\n",
    "proc.time() - ptm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      "NULL\n"
     ]
    }
   ],
   "source": [
    "print (printSchema(movielens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1659361605"
      ],
      "text/latex": [
       "1659361605"
      ],
      "text/markdown": [
       "1659361605"
      ],
      "text/plain": [
       "[1] 1659361605"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.018   0.006 284.034 "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptm <- proc.time()\n",
    "count (reddit)\n",
    "proc.time() - ptm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sqlContext <- sparkRSQL.init(sc)\n",
    "#df <- read.df(sqlContext, \"hdfs:///repository/reddit/data_0.csv\", source=\"com.databricks.spark.csv\")\n",
    "#head(df)\n",
    "#df <- createDataFrame(sqlContext, faithful)\n",
    "#head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparkR.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "r-3.3"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
